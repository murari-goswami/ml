{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "#from model import StackedAutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CDAutoEncoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    Convolutional denoising autoencoder layer for stacked autoencoders.\n",
    "    This module is automatically trained when in model.training is True.\n",
    "    Args:\n",
    "        input_size: The number of features in the input\n",
    "        output_size: The number of features to output\n",
    "        stride: Stride of the convolutional layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, stride):\n",
    "        super(CDAutoEncoder, self).__init__()\n",
    "\n",
    "        self.forward_pass = nn.Sequential(\n",
    "            nn.Conv2d(input_size, output_size, kernel_size=2, stride=stride, padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.backward_pass = nn.Sequential(\n",
    "            nn.ConvTranspose2d(output_size, input_size, kernel_size=2, stride=2, padding=0), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Train each autoencoder individually\n",
    "        x = x.detach()\n",
    "        # Add noise, but use the original lossless input as the target.\n",
    "        x_noisy = x * (Variable(x.data.new(x.size()).normal_(0, 0.1)) > -.1).type_as(x)\n",
    "        y = self.forward_pass(x_noisy)\n",
    "\n",
    "        if self.training:\n",
    "            x_reconstruct = self.backward_pass(y)\n",
    "            loss = self.criterion(x_reconstruct, Variable(x.data, requires_grad=False))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return y.detach()\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "        return self.backward_pass(x)\n",
    "\n",
    "\n",
    "class StackedAutoEncoder(nn.Module):\n",
    "    r\"\"\"\n",
    "    A stacked autoencoder made from the convolutional denoising autoencoders above.\n",
    "    Each autoencoder is trained independently and at the same time.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StackedAutoEncoder, self).__init__()\n",
    "\n",
    "        self.ae1 = CDAutoEncoder(3, 128, 2)\n",
    "        self.ae2 = CDAutoEncoder(128, 256, 2)\n",
    "        self.ae3 = CDAutoEncoder(256, 512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a1 = self.ae1(x)\n",
    "        a2 = self.ae2(a1)\n",
    "        a3 = self.ae3(a2)\n",
    "\n",
    "        if self.training:\n",
    "            return a3\n",
    "\n",
    "        else:\n",
    "            return a3, self.reconstruct(a3)\n",
    "\n",
    "    def reconstruct(self, x):\n",
    "            a2_reconstruct = self.ae3.reconstruct(x)\n",
    "            a1_reconstruct = self.ae2.reconstruct(a2_reconstruct)\n",
    "            x_reconstruct = self.ae1.reconstruct(a1_reconstruct)\n",
    "            return x_reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./imgs'):\n",
    "    os.mkdir('./imgs')\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 3, 32, 32)\n",
    "    return x\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(360),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0, hue=0),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CIFAR10('representation_learning/input/', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "model = StackedAutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving epoch 0\n",
      "Epoch 0 complete\tTime: 128.4477s\t\tLoss: 0.1260\n",
      "Feature Statistics\tMean: 0.1390\t\tMax: 1.9145\t\tSparsity: 48.0000%\n",
      "Linear classifier performance: 11273/50048 = 22.52%\n",
      "================================================================================\n",
      "Saving epoch 1\n",
      "Epoch 1 complete\tTime: 128.7212s\t\tLoss: 0.1073\n",
      "Feature Statistics\tMean: 0.1429\t\tMax: 2.1808\t\tSparsity: 48.0000%\n",
      "Linear classifier performance: 10632/50048 = 21.24%\n",
      "================================================================================\n",
      "Saving epoch 2\n",
      "Epoch 2 complete\tTime: 113.2883s\t\tLoss: 0.0676\n",
      "Feature Statistics\tMean: 0.1378\t\tMax: 2.0949\t\tSparsity: 49.0000%\n",
      "Linear classifier performance: 11023/50048 = 22.02%\n",
      "================================================================================\n",
      "Saving epoch 3\n",
      "Epoch 3 complete\tTime: 130.5793s\t\tLoss: 0.0614\n",
      "Feature Statistics\tMean: 0.1427\t\tMax: 2.1215\t\tSparsity: 49.0000%\n",
      "Linear classifier performance: 10649/50048 = 21.28%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    if epoch % 1 == 0:\n",
    "        # Test the quality of our features with a randomly initialzed linear classifier.\n",
    "        classifier = nn.Linear(512 * 16, 10)#.cuda()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    total_time = time.time()\n",
    "    correct = 0\n",
    "    for i, data in enumerate(dataloader):\n",
    "        img, target = data\n",
    "        target = Variable(target)#.cuda()\n",
    "        img = Variable(img)#.cuda()\n",
    "        features = model(img)#.detach()\n",
    "        prediction = classifier(features.view(features.size(0), -1))\n",
    "        loss = criterion(prediction, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = prediction.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    total_time = time.time() - total_time\n",
    "\n",
    "    model.eval()\n",
    "    img, _ = data\n",
    "    img = Variable(img)#.cuda()\n",
    "    features, x_reconstructed = model(img)\n",
    "    reconstruction_loss = torch.mean((x_reconstructed.data - img.data)**2)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(\"Saving epoch {}\".format(epoch))\n",
    "        orig = to_img(img.cpu().data)\n",
    "        save_image(orig, './imgs/orig_{}.png'.format(epoch))\n",
    "        pic = to_img(x_reconstructed.cpu().data)\n",
    "        save_image(pic, './imgs/reconstruction_{}.png'.format(epoch))\n",
    "\n",
    "    print(\"Epoch {} complete\\tTime: {:.4f}s\\t\\tLoss: {:.4f}\".format(epoch, total_time, reconstruction_loss))\n",
    "    print(\"Feature Statistics\\tMean: {:.4f}\\t\\tMax: {:.4f}\\t\\tSparsity: {:.4f}%\".format(\n",
    "        torch.mean(features.data), torch.max(features.data), torch.sum(features.data == 0.0)*100 / features.data.numel())\n",
    "    )\n",
    "    print(\"Linear classifier performance: {}/{} = {:.2f}%\".format(correct, len(dataloader)*batch_size, 100*float(correct) / (len(dataloader)*batch_size)))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "torch.save(model.state_dict(), './CDAE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
